{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8675c2e",
   "metadata": {},
   "source": [
    "# Domain Separation Network (DSN) Pipeline\n",
    "This notebook implements the DSN architecture for unsupervised domain adaptation in speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b907c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jiwer version: 4.0.0\n",
      "editdistance version: 0.8.1\n",
      "editdistance available: 3\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata\n",
    "import editdistance, jiwer\n",
    "\n",
    "print(\"jiwer version:\", importlib.metadata.version(\"jiwer\"))\n",
    "print(\"editdistance version:\", importlib.metadata.version(\"editdistance\"))\n",
    "print(\"editdistance available:\", editdistance.eval(\"kitten\", \"sitting\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33647762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Imports & device\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ede18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Collate fn for variable-length utterances (pad to max-T per batch)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Handles variable-length feature sequences (and optional labels).\n",
    "\n",
    "    batch:\n",
    "      - source: list of (features[T,F], labels[T]) tuples\n",
    "      - target: list of features[T,F]\n",
    "\n",
    "    Returns:\n",
    "      source -> (padded_feats[B,T,F], padded_labels[B,T], lengths[B])\n",
    "      target -> (padded_feats[B,T,F], lengths[B])\n",
    "    \"\"\"\n",
    "    if isinstance(batch[0], tuple):  # source (features, labels)\n",
    "        feats, labels = zip(*batch)  # each feats: [T,F], labels: [T]\n",
    "        lengths = torch.tensor([f.size(0) for f in feats], dtype=torch.long)\n",
    "        padded_feats = pad_sequence(feats, batch_first=True)               # [B,T,F]\n",
    "        padded_labels = pad_sequence(labels, batch_first=True, padding_value=-100)  # [B,T]\n",
    "        return padded_feats, padded_labels, lengths\n",
    "    else:  # target (features only)\n",
    "        feats = batch\n",
    "        lengths = torch.tensor([f.size(0) for f in feats], dtype=torch.long)\n",
    "        padded_feats = pad_sequence(feats, batch_first=True)               # [B,T,F]\n",
    "        return padded_feats, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2819756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Lazy .npy datasets (per-utterance files), optional labels\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "class LazyNPYDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Lazy loading dataset for .npy feature files and optional labels.\n",
    "    Assumes: one .npy per utterance. If labels provided, filenames match.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dir, label_dir=None, feature_dtype=np.float32):\n",
    "        self.feature_dir = feature_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.file_list = sorted([f for f in os.listdir(feature_dir) if f.endswith(\".npy\")])\n",
    "        self.feature_dtype = feature_dtype\n",
    "\n",
    "        if label_dir:\n",
    "            self.label_list = sorted([f for f in os.listdir(label_dir) if f.endswith(\".npy\")])\n",
    "            assert len(self.file_list) == len(self.label_list), \\\n",
    "                f\"Mismatch: {len(self.file_list)} feature files vs {len(self.label_list)} label files\"\n",
    "            # Optional: verify same basenames\n",
    "            for f_feat, f_lab in zip(self.file_list, self.label_list):\n",
    "                assert os.path.splitext(f_feat)[0] == os.path.splitext(f_lab)[0], \\\n",
    "                    f\"Filename mismatch: {f_feat} vs {f_lab}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def _load_npy(self, path, dtype=None):\n",
    "        arr = np.load(path, allow_pickle=False)\n",
    "        if dtype is not None and arr.dtype != dtype:\n",
    "            arr = arr.astype(dtype, copy=False)\n",
    "        return arr\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat_path = os.path.join(self.feature_dir, self.file_list[idx])\n",
    "        features = self._load_npy(feat_path, dtype=self.feature_dtype)     # [T,F]\n",
    "        features = torch.as_tensor(features, dtype=torch.float32)\n",
    "\n",
    "        if self.label_dir:\n",
    "            label_path = os.path.join(self.label_dir, self.label_list[idx])\n",
    "            labels = self._load_npy(label_path)                             # [T] (per-frame senone id)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.long)\n",
    "            return features, labels\n",
    "        else:\n",
    "            return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8a9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Model components\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def _mlp_stack(in_dim, hidden_dim, num_layers):\n",
    "    layers = []\n",
    "    for _ in range(num_layers):\n",
    "        layers += [nn.Linear(in_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU()]\n",
    "        in_dim = hidden_dim\n",
    "    return nn.Sequential(*layers), in_dim\n",
    "\n",
    "def build_private_encoder(input_dim=1320, hidden_dim=512, num_layers=4):\n",
    "    seq, _ = _mlp_stack(input_dim, hidden_dim, num_layers)\n",
    "    return seq  # outputs [N, hidden_dim]\n",
    "\n",
    "def build_shared_encoder(input_dim=1320, hidden_dim=1024, num_layers=6):\n",
    "    seq, out_dim = _mlp_stack(input_dim, hidden_dim, num_layers)\n",
    "    assert out_dim == hidden_dim\n",
    "    return seq  # outputs [N, hidden_dim]\n",
    "\n",
    "def build_decoder(bottleneck_dim=1024, output_dim=1320, num_layers=3):\n",
    "    layers = []\n",
    "    in_dim = bottleneck_dim\n",
    "    for _ in range(num_layers):\n",
    "        layers += [nn.Linear(in_dim, in_dim), nn.BatchNorm1d(in_dim), nn.ReLU()]\n",
    "    layers += [nn.Linear(in_dim, output_dim)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def build_classifier(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "        nn.Linear(1024, output_dim)\n",
    "    )\n",
    "\n",
    "def build_domain_classifier(input_dim, hidden_dim=256):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, 2)  # 0=source, 1=target\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a15293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Losses\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def diff_loss(private_feat, shared_feat):\n",
    "    \"\"\"\n",
    "    L_diff: encourage orthogonality between private and shared spaces.\n",
    "    private_feat, shared_feat: [N, Dp], [N, Ds]\n",
    "    \"\"\"\n",
    "    # Use normalized Frobenius norm of cross-covariance\n",
    "    batch = private_feat.size(0)\n",
    "    return torch.norm(private_feat.T @ shared_feat, p='fro') / max(batch, 1)\n",
    "\n",
    "def recon_loss(original, reconstructed):\n",
    "    \"\"\"L_recon: reconstruct input from (shared + private).\"\"\"\n",
    "    return nn.functional.mse_loss(reconstructed, original, reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4212eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 6) DSN wrapper\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "class DSN(nn.Module):\n",
    "    def __init__(self, input_dim=1320, num_senones=3080, shared_dim=1024):\n",
    "        super().__init__()\n",
    "        # private encoders same output dim as shared encoder\n",
    "        self.private_s = build_private_encoder(input_dim, shared_dim, num_layers=4)\n",
    "        self.private_t = build_private_encoder(input_dim, shared_dim, num_layers=4)\n",
    "        self.shared = build_shared_encoder(input_dim, shared_dim, num_layers=6)\n",
    "        self.decoder = build_decoder(shared_dim, input_dim, num_layers=3)\n",
    "\n",
    "        self.senone_classifier = build_classifier(shared_dim, num_senones)\n",
    "        self.domain_classifier = build_domain_classifier(shared_dim)\n",
    "\n",
    "    def forward(self, x, mode='source'):\n",
    "        \"\"\"\n",
    "        x: [N, F]\n",
    "        mode: 'source' or 'target'\n",
    "        \"\"\"\n",
    "        private = self.private_s(x) if mode == 'source' else self.private_t(x)\n",
    "        shared = self.shared(x)\n",
    "        recon = self.decoder(shared + private)\n",
    "\n",
    "        senone_logits = self.senone_classifier(shared) if mode == 'source' else None\n",
    "        domain_logits = self.domain_classifier(shared)\n",
    "\n",
    "        return {\n",
    "            \"private\": private,\n",
    "            \"shared\": shared,\n",
    "            \"recon\": recon,\n",
    "            \"senone_logits\": senone_logits,\n",
    "            \"domain_logits\": domain_logits\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca9f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 7) DataLoaders & training\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def make_loader(dataset, batch_size=32, shuffle=True):\n",
    "    return DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        pin_memory=True, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "def get_dataloaders(path1, path2, sanskrit_train, sanskrit_test, batch_size=32):\n",
    "    src_train = LazyNPYDataset(path1, path2)     # (x,y)\n",
    "    tgt_train = LazyNPYDataset(sanskrit_train)   # x only\n",
    "    tgt_test  = LazyNPYDataset(sanskrit_test)    # x only\n",
    "\n",
    "    return (\n",
    "        make_loader(src_train, batch_size=batch_size, shuffle=True),\n",
    "        make_loader(tgt_train, batch_size=batch_size, shuffle=True),\n",
    "        make_loader(tgt_test,  batch_size=batch_size, shuffle=False),\n",
    "    )\n",
    "\n",
    "def flatten_batch_time(x_bt_f):\n",
    "    \"\"\"[B,T,F] -> [B*T, F]\"\"\"\n",
    "    return x_bt_f.view(-1, x_bt_f.size(-1))\n",
    "\n",
    "def flatten_labels(y_bt):\n",
    "    \"\"\"[B,T] -> [B*T]\"\"\"\n",
    "    return y_bt.reshape(-1)\n",
    "\n",
    "def train_dsn(model, src_loader, tgt_loader, num_epochs=20,\n",
    "              alpha=0.25, beta=0.075, gamma=0.1, lr=0.01):\n",
    "    \"\"\"\n",
    "    Total loss = L_cls + alpha*L_domain + beta*L_diff + gamma*L_recon\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    ce = nn.CrossEntropyLoss(ignore_index=-100)  # ignore padded labels\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        # zip will stop at the shorter loader (OK for UDA)\n",
    "        for (src_x, src_y, _), (tgt_x, _) in zip(src_loader, tgt_loader):\n",
    "            src_x = src_x.to(device, non_blocking=True)  # [B,T,F]\n",
    "            src_y = src_y.to(device, non_blocking=True)  # [B,T]\n",
    "            tgt_x = tgt_x.to(device, non_blocking=True)  # [B,T,F]\n",
    "\n",
    "            # flatten to per-frame\n",
    "            src_xf = flatten_batch_time(src_x)  # [N,F]\n",
    "            tgt_xf = flatten_batch_time(tgt_x)  # [N,F]\n",
    "            src_yf = flatten_labels(src_y)      # [N]\n",
    "\n",
    "            # forward\n",
    "            out_s = model(src_xf, mode='source')\n",
    "            out_t = model(tgt_xf, mode='target')\n",
    "\n",
    "            # losses\n",
    "            l_cls  = ce(out_s[\"senone_logits\"], src_yf)\n",
    "            dom_s  = torch.zeros(src_xf.size(0), dtype=torch.long, device=device)\n",
    "            dom_t  = torch.ones (tgt_xf.size(0), dtype=torch.long, device=device)\n",
    "            l_dom  = ce(out_s[\"domain_logits\"], dom_s) + ce(out_t[\"domain_logits\"], dom_t)\n",
    "            l_diff = diff_loss(out_s[\"private\"], out_s[\"shared\"]) + diff_loss(out_t[\"private\"], out_t[\"shared\"])\n",
    "            l_rec  = recon_loss(src_xf, out_s[\"recon\"]) + recon_loss(tgt_xf, out_t[\"recon\"])\n",
    "\n",
    "            loss = l_cls + alpha*l_dom + beta*l_diff + gamma*l_rec\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running += loss.item()\n",
    "            steps += 1\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{num_epochs} | Avg loss: {running/max(steps,1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da5eefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/20 | Avg loss: 8.0693\n",
      "Epoch 02/20 | Avg loss: 3.2824\n",
      "Epoch 03/20 | Avg loss: 2.9245\n",
      "Epoch 04/20 | Avg loss: 2.7586\n",
      "Epoch 05/20 | Avg loss: 2.5964\n",
      "Epoch 06/20 | Avg loss: 2.4429\n",
      "Epoch 07/20 | Avg loss: 2.3908\n",
      "Epoch 08/20 | Avg loss: 2.2921\n",
      "Epoch 09/20 | Avg loss: 2.2524\n",
      "Epoch 10/20 | Avg loss: 2.1740\n",
      "Epoch 11/20 | Avg loss: 2.1843\n",
      "Epoch 12/20 | Avg loss: 2.1048\n",
      "Epoch 13/20 | Avg loss: 2.0864\n",
      "Epoch 14/20 | Avg loss: 2.0719\n",
      "Epoch 15/20 | Avg loss: 2.0752\n",
      "Epoch 16/20 | Avg loss: 2.0412\n",
      "Epoch 17/20 | Avg loss: 1.9732\n",
      "Epoch 18/20 | Avg loss: 1.9297\n",
      "Epoch 19/20 | Avg loss: 1.9885\n",
      "Epoch 20/20 | Avg loss: 1.8976\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 8) Example usage (set your actual folders)\n",
    "#    As you asked earlier: keep feature folder as path1 etc.\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CHANGE THESE to your real paths:\n",
    "path1 = r\"C:\\npy_feats\\hindi\"          # Hindi features (.npy per utterance)\n",
    "path2 = r\"C:\\senone_labels\"     # Matching senone labels (.npy per utterance)\n",
    "sanskrit_train = r\"C:\\npy_feats\\sanskrit_train\" # Sanskrit train features (.npy per utt)\n",
    "sanskrit_test  = r\"C:\\npy_feats\\sanskrit_test\"  # Sanskrit test features (.npy per utt)\n",
    "\n",
    "batch_size = 16\n",
    "src_loader, tgt_loader, tgt_test_loader = get_dataloaders(\n",
    "    path1, path2, sanskrit_train, sanskrit_test, batch_size=batch_size\n",
    ")\n",
    "\n",
    "dsn_model = DSN(input_dim=1320, num_senones=3080).to(device)\n",
    "train_dsn(dsn_model, src_loader, tgt_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a4272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.000\n",
      "CER: 0.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 9) Model evaluation: inference on test set + WER & CER\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "import os\n",
    "from jiwer import wer\n",
    "import editdistance\n",
    "\n",
    "# Path to transcript file (update this)\n",
    "transcript_file = r\"C:\\Users\\prasu\\Desktop\\filtered_transcripts.txt\"\n",
    "\n",
    "# Load reference transcripts\n",
    "references = {}\n",
    "with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"|\")\n",
    "        if len(parts) == 2:\n",
    "            filename, transcript = parts\n",
    "            npy_filename = filename.replace(\".m4a\", \".npy\")\n",
    "            references[npy_filename] = transcript.lower()\n",
    "\n",
    "# Run inference on test set\n",
    "dsn_model.eval()\n",
    "predictions = {}\n",
    "with torch.no_grad():\n",
    "    for feats, lengths, fnames in tgt_test_loader:\n",
    "        feats = feats.to(device)\n",
    "        xf = feats.view(-1, feats.size(-1))\n",
    "        out = dsn_model(xf, mode='target')\n",
    "        if out[\"senone_logits\"] is None:\n",
    "            continue\n",
    "\n",
    "        pred_ids = out[\"senone_logits\"].argmax(dim=-1).cpu().numpy().tolist()\n",
    "        pred_str = \" \".join(map(str, pred_ids))   # convert to space-separated string\n",
    "\n",
    "        for fname in fnames:\n",
    "            predictions[fname] = pred_str\n",
    "\n",
    "\n",
    "# Align predictions and references\n",
    "y_true, y_pred = [], []\n",
    "for fname, ref_text in references.items():\n",
    "    if fname in predictions:\n",
    "        y_true.append(ref_text)\n",
    "        y_pred.append(predictions[fname])\n",
    "\n",
    "# Compute WER and CER\n",
    "wer_score = wer(y_true, y_pred)\n",
    "\n",
    "def cer(r, h):\n",
    "    return editdistance.eval(r, h) / len(r) if len(r) > 0 else 0\n",
    "\n",
    "cer_scores = [cer(r, h) for r, h in zip(y_true, y_pred)]\n",
    "cer_score = sum(cer_scores) / len(cer_scores) if cer_scores else 0\n",
    "\n",
    "print(f\"WER: {wer_score:.3f}\")\n",
    "print(f\"CER: {cer_score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
